# -*- coding: utf-8 -*-
"""web crawling.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1e9Af9ypsaLDB-SFcWADTg8d6xkMGp3uD
"""

pip install beautifulsoup4 requests pandas matplotlib seaborn

import requests
from bs4 import BeautifulSoup
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import json

# 네이버 블로그 검색 URL 기반
base_url = "https://section.blog.naver.com/Search/Post.naver?pageNo=1&rangeType=ALL&orderBy=sim&keyword="

# 검색어 설정 ('잠실종합운동장맛집', '올림픽공원맛집')
keywords = ["잠실종합운동장맛집", "올림픽공원맛집"]

places = []

for keyword in keywords:
    url = base_url + keyword
    response = requests.get(url)
    soup = BeautifulSoup(response.text, 'html.parser')

print(soup)

# 블로그 포스트에서 포스트 URL 찾기
    blog_posts = soup.find_all('a', {'class': 'desc_inner'})
    for post in blog_posts:
        post_url = "https://blog.naver.com" + post['href']

        # 포스트에 접근하여 본문 내용 가져오기
        post_response = requests.get(post_url)
        post_soup = BeautifulSoup(post_response.text, 'html.parser')

# 본문에서 name, address 정보 가져오기
        map_texts = post_soup.find_all('div', {'class': 'se-module se-module-map-text'})
        for map_text in map_texts:
          a_tag = map_text.find('a')
          if a_tag and a_tag['data-linkdata']:
            linkdata = a_tag['data-linkdata']
            linkdata_dict = json.loads(linkdata)
            places.append(linkdata_dict['name'])

# 데이터 프레임 생성 및 출력
df = pd.DataFrame(places, columns=['Place'])
print(df['Place'].value_counts())

# 데이터 시각화
plt.figure(figsize=(10,6))
sns.countplot(y = "Place", data = df, order = df['Place'].value_counts().index)
plt.show()

"""## **다시!!!**"""

import pandas as pd
import numpy as np


# csv 파일이되 데이터 구분을 '|' 로 해둔 파일입니다. sep 지정을 안 하면 읽을 수 없습니다.
df = pd.read_csv('foodshop.csv')

df.columns

# 음식점 데이터만 쓸 겁니다
df = df[df['상권업종대분류명'] == '음식']

# 다음과 같은 칼럼만 있으면 됩니다
df = df[['상호명', '상권업종중분류명', '상권업종소분류명', '표준산업분류명', '행정동명', '위도', '경도']]
# 올림픽
df_ol = df.loc[(df['행정동명'] == '성내1동') | (df['행정동명'] == '방이1동')| (df['행정동명'] == '방이2동')| (df['행정동명'] == '오륜동')| (df['행정동명'] == '성내3동')| (df['행정동명'] == '송파1동')]
#잠실종합운동장
df_jam = df.loc[(df['행정동명'] == '잠실7동')|(df['행정동명'] == '잠실2동')|(df['행정동명'] == '잠실본동')|(df['행정동명'] == '잠실3동')]

df.columns = ['name',  # 상호명
              'cate_1',  # 중분류명
              'cate_2',  # 소분류명
              'cate_3',  # 표준산업분류명
              'dong',  # 행정동명
              'lon',  # 위도
              'lat'  # 경도
              ]
df_ol.columns = ['name',  # 상호명
              'cate_1',  # 중분류명
              'cate_2',  # 소분류명
              'cate_3',  # 표준산업분류명
              'dong',  # 행정동명
              'lon',  # 위도
              'lat'  # 경도
              ]
df_jam.columns = ['name',  # 상호명
              'cate_1',  # 중분류명
              'cate_2',  # 소분류명
              'cate_3',  # 표준산업분류명
              'dong',  # 행정동명
              'lon',  # 위도
              'lat'  # 경도
              ]

#올림픽
df['cate_3']= df['cate_3'].str.replace(" ","")
df_ol['cate_mix'] = df_ol['cate_1'] + "  /  "+df_ol['cate_2'] + "  /  "+ df_ol['cate_3']
#df_ol['cate_mix'] = df_ol['cate_mix'].str.replace("/", " ")

df_ol

#잠실
df_jam['cate_mix'] = df_jam['cate_1'] + df_jam['cate_2'] +  df_jam['cate_3']
df_jam['cate_mix'] = df_jam['cate_mix'].str.replace("/", " ")

